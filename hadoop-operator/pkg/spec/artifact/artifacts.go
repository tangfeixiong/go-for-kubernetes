// Code generated by go-bindata.
// sources:
// template/core-site.xml.gotpl
// template/hdfs-node-service.yaml.gotpl
// template/hdfs-node-statefulset.yaml.gotpl
// template/hdfs-site.xml.gotpl
// template/mapred-site.xml.gotpl
// template/yarn-site.xml.gotpl
// DO NOT EDIT!

package artifact

import (
	"fmt"
	"io/ioutil"
	"os"
	"path/filepath"
	"strings"
	"time"
)
type asset struct {
	bytes []byte
	info  os.FileInfo
}

type bindataFileInfo struct {
	name    string
	size    int64
	mode    os.FileMode
	modTime time.Time
}

func (fi bindataFileInfo) Name() string {
	return fi.name
}
func (fi bindataFileInfo) Size() int64 {
	return fi.size
}
func (fi bindataFileInfo) Mode() os.FileMode {
	return fi.mode
}
func (fi bindataFileInfo) ModTime() time.Time {
	return fi.modTime
}
func (fi bindataFileInfo) IsDir() bool {
	return false
}
func (fi bindataFileInfo) Sys() interface{} {
	return nil
}

var _templateCoreSiteXmlGotpl = []byte(`<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
  <property>
    <name>fs.defaultFS</name>
	<value>hdfs://{{.NameNodeHost}}:9000</value>
	<description>NameNode URI. hdfs://host:port/</description>
  </property>

  <property>
	<name>io.file.buffer.size</name>
	<value>131072</value>
	<description>Size of read/write buffer used in SequenceFiles.</description>
  </property>
</configuration>
`)

func templateCoreSiteXmlGotplBytes() ([]byte, error) {
	return _templateCoreSiteXmlGotpl, nil
}

func templateCoreSiteXmlGotpl() (*asset, error) {
	bytes, err := templateCoreSiteXmlGotplBytes()
	if err != nil {
		return nil, err
	}

	info := bindataFileInfo{name: "template/core-site.xml.gotpl", size: 1099, mode: os.FileMode(420), modTime: time.Unix(1517756440, 0)}
	a := &asset{bytes: bytes, info: info}
	return a, nil
}

var _templateHdfsNodeServiceYamlGotpl = []byte(`apiVersion: v1
kind: Service
metadata:
  labels:
    app: hadoop
    example.com/rabbitmq-operator: {{ .CustomResourceName }} # operator reserved!
    github.com/go-to-kubernetes: hadoop-operator
  name: {{ .Name }} # e.g. demo-hadoop-namenode
  #namespace: {{ .Namespace }}
spec:
  clusterIP: None
  ports:
  - name: hdfs
    port: 9000
    protocol: TCP
    targetPort: 9000
  selector:
    app: hadoop
    example.com/rabbitmq-operator: {{ .CustomResourceName }} # required by operator itself!
    github.com/go-to-kubernetes: hadoop-operator
  #sessionAffinity: None
  #sessionAffinity: ClientIP
  #type: ClusterIP`)

func templateHdfsNodeServiceYamlGotplBytes() ([]byte, error) {
	return _templateHdfsNodeServiceYamlGotpl, nil
}

func templateHdfsNodeServiceYamlGotpl() (*asset, error) {
	bytes, err := templateHdfsNodeServiceYamlGotplBytes()
	if err != nil {
		return nil, err
	}

	info := bindataFileInfo{name: "template/hdfs-node-service.yaml.gotpl", size: 618, mode: os.FileMode(420), modTime: time.Unix(1517766170, 0)}
	a := &asset{bytes: bytes, info: info}
	return a, nil
}

var _templateHdfsNodeStatefulsetYamlGotpl = []byte(`apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  labels:
    app: hadoop
    example.com/hadoop-operator: {{.CustomResourceName }} # required by operator itself!
    github.com/go-to-kubernetes: hadoop-operator
  name: {{.Name }} # e.g. demo-hadoop-namenode
  #namespace: {{.Namespace}}
spec:
  podManagementPolicy: OrderedReady
  #podManagementPolicy: Parallel
  replicas: {{.Count}}
  selector:
    matchLabels:
      app: hadoop
      example.com/hadoop-operator: {{.CustomResourceName}} # required by operator itself!
      github.com/go-to-kubernetes: hadoop-operator
  serviceName: {{.ServiceName}} # e.g. demo-hadoop-galera
  template:
    metadata:
      labels:
        app: hadoop
        app-affinity: local-test-affinity
        example.com/hadoop-operator: {{.CustomResourceName}} # required by operator itself!
        github.com/go-to-kubernetes: hadoop-operator
        hadoop-operator: {{.Name}} # required by operator itself!
        node-type: {{.HdfsNodeType}}
    spec:
      #affinity:
      #  podAffinity:
      #    requiredDuringSchedulingIgnoredDuringExecution:
      #    - labelSelector:
      #        matchExpressions:
      #        - key: app-affinity
      #          operator: In
      #          values:
      #          - local-test-affinity
      #      topologyKey: kubernetes.io/hostname
      #affinity:
      #  podAntiAffinity:
      #    requiredDuringSchedulingIgnoredDuringExecution:
      #    - labelSelector:
      #        matchExpressions:
      #        - key: app-affinity
      #          operator: In
      #          values:
      #          - local-test-anti-affinity
      #      topologyKey: kubernetes.io/hostname
      containers:
      - args:
        - {{.HdfsNodeType}}
        command:
        - /hadoop-3.0.0/bin/hdfs
        env:
        - name: MY_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: docker.io/tangfeixiong/hadoop
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        #livenessProbe:
        #  exec:
        #    command:
        #    - /hadoop-3.0.0/bin/hadoop
        #    - status
        #  failureThreshold: 6
        #  initialDelaySeconds: 30
        #  periodSeconds: 10
        #  successThreshold: 1
        #  timeoutSeconds: 10
        name: hadoop
        ports:
        - containerPort: 9000
          name: hdfs
          protocol: TCP
        #readinessProbe:
        #  exec:
        #    command:
        #    - /hadoop-3.0.0/bin/hadoop
        #    - status
        #  failureThreshold: 3
        #  initialDelaySeconds: 10
        #  periodSeconds: 3
        #  successThreshold: 1
        #  timeoutSeconds: 10
        resources: {}
        securityContext: {}
        #serviceAccountName: hadoop
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /hadoop-3.0.0/etc/hadoop
          name: hadoopetc
        - mountPath: /tmp/hadoop-3.0.00x2Fetc0x2Fhadoop
          name: conf
        - mountPath: /tmp/hadoop-root
          #name: local-vol
          name: hostpath
      dnsPolicy: ClusterFirst
      initContainers:
      - args:
        - --conf_dir=/hadoop-3.0.0/etc/hadoop
        {{with .HdfsClusterID}}- --hdfs_cluster_id={{.}}{{end}}
        - --hdfs_node_type={{.HdfsNodeType}}
        - --logtostderr
        - --v=5
        command:
        - /hadoop-operator
        - init
        env:
        - name: MY_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: MY_POD_NAME  # important, required to discover StatefulSet name by operator itself!
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        #- name: MY_POD_SERVICE_ACCOUNT
        #  valueFrom:
        #    fieldRef:
        #      fieldPath: spec.serviceAccountName
        image: docker.io/tangfeixiong/hadoop-agent
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        name: agent
        resources: {}
        securityContext: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /tmp/hadoop-3.0.00x2Fetc0x2Fhadoop
          name: conf
        - mountPath: /tmp/hadoop-root
          #name: local-vol
          name: hostpath
        - mountPath: /tmp/podinfo
          name: podinfo
      #restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      #securityContext:
      #  fsGroup: 1234
      #serviceAccountName: hadoop
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          name: {{.CustomResourceName}}--{{.Name}}
          items:
          - key: core-site.xml  # .$(MY_NODE_NAME)
            path: core-site.xml
          - key: hdfs-site.xml
            path: hdfs-site.xml
          - key: yarn-site.xml
            path: yarn-site.xml
          - key: mapred-site.xml
            path: mapred-site.xml
        name: hadoopetc
      - downwardAPI:
          defaultMode: 420
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.annotations
            path: annotations
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels
            path: labels
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
            path: name
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
        name: podinfo
      - emptyDir: {}
        name: conf
  updateStrategy:
    #type: RollingUpdate
    type: OnDelete
  volumeClaimTemplates:
  #- metadata:
  #    name: local-vol
  #  spec:
  #    accessModes: [ "ReadWriteOnce" ]
  #    storageClassName: "local-storage"
  #    resources:
  #      requests:
  #        storage: 100Mi
  - metadata:
      name: hostpath
      #annotations:
      #  volume.beta.kubernetes.io/storage-class: "example-hostpath"
    spec:
      accessModes:
        - ReadWriteOnce
        #- ReadOnlyMany
        #- ReadWriteMany
      storageClassName: "example-hostpath"
      resources:
        requests:
          storage: 80Mi
    `)

func templateHdfsNodeStatefulsetYamlGotplBytes() ([]byte, error) {
	return _templateHdfsNodeStatefulsetYamlGotpl, nil
}

func templateHdfsNodeStatefulsetYamlGotpl() (*asset, error) {
	bytes, err := templateHdfsNodeStatefulsetYamlGotplBytes()
	if err != nil {
		return nil, err
	}

	info := bindataFileInfo{name: "template/hdfs-node-statefulset.yaml.gotpl", size: 6602, mode: os.FileMode(420), modTime: time.Unix(1517855354, 0)}
	a := &asset{bytes: bytes, info: info}
	return a, nil
}

var _templateHdfsSiteXmlGotpl = []byte(`<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<configuration>
  <!-- Configurations for NameNode: -->
  <property>
    <name>dfs.namenode.name.dir</name>
	<value></value>
	<description>Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently. If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.</description>
  </property>

  <property>
	<name>dfs.hosts</name>
	<value></value>
	<description>If necessary, use these files to control the list of allowable datanodes.</description>
  </property>

  <property>
    <name>dfs.hosts.exclude</name>
	<value></value>
	<description>List of permitted/excluded DataNodes. If necessary, use these files to control the list of allowable datanodes.</description>
  </property>

  <property>
    <name>dfs.blocksize</name>
	<value>268435456</value>
	<description>HDFS blocksize of 256MB for large file-systems.</description>
  </property>

  <property>
    <name>dfs.namenode.handler.count</name>
	<value>100</value>
	<description>More NameNode server threads to handle RPCs from large number of DataNodes.</description>
  </property>
	
  <!-- Configurations for DataNode: -->
  <property>
    <name>dfs.datanode.data.dir</name>
	<value></value>
	<description>Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks. If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices.</description>
  </property>
	
</configuration>
`)

func templateHdfsSiteXmlGotplBytes() ([]byte, error) {
	return _templateHdfsSiteXmlGotpl, nil
}

func templateHdfsSiteXmlGotpl() (*asset, error) {
	bytes, err := templateHdfsSiteXmlGotplBytes()
	if err != nil {
		return nil, err
	}

	info := bindataFileInfo{name: "template/hdfs-site.xml.gotpl", size: 2139, mode: os.FileMode(420), modTime: time.Unix(1517753137, 0)}
	a := &asset{bytes: bytes, info: info}
	return a, nil
}

var _templateMapredSiteXmlGotpl = []byte(`<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
  <!-- Configurations for MapReduce Applications: -->
  <property>
    <name>mapreduce.framework.name</name>
	<value>yarn</value>
	<description>Execution framework set to Hadoop YARN.</description>
  </property>

  <property>
    <name>mapreduce.map.memory.mb</name>
	<value>1536</value>
	<description>Larger resource limit for maps.</description>
  </property>

  <property>
    <name>mapreduce.map.java.opts</name>
	<value>-Xmx1024M</value>
	<description>Larger heap-size for child jvms of maps.</description>
  </property>

  <property>
    <name>mapreduce.reduce.memory.mb</name>
	<value>3072</value>
	<description>Larger resource limit for reduces.</description>
  </property>

  <property>
    <name>mapreduce.reduce.java.opts</name>
	<value>-Xmx2560M</value>
	<description>Larger heap-size for child jvms of reduces.</description>
  </property>

  <property>
    <name>mapreduce.task.io.sort.mb</name>
	<value>512</value>
	<description>Higher memory-limit while sorting data for efficiency.</description>
  </property>

  <property>
    <name>mapreduce.task.io.sort.factor</name>
	<value>100</value>
	<description>More streams merged at once while sorting files.</description>
  </property>

  <property>
    <name>mapreduce.reduce.shuffle.parallelcopies</name>
	<value>50</value>
	<description>Higher number of parallel copies run by reduces to fetch outputs from very large number of maps.</description>
  </property>

  <!-- Configurations for MapReduce JobHistory Server: -->
  <property>
    <name>mapreduce.jobhistory.address</name>
	<value></value>
	<description>MapReduce JobHistory Server host:port	Default port is 10020.</description>
  </property>

  <property>
    <name>mapreduce.jobhistory.webapp.address</name>
	<value></value>
	<description>MapReduce JobHistory Server Web UI host:port	Default port is 19888.</description>
  </property>

  <property>
    <name>mapreduce.jobhistory.intermediate-done-dir</name>
	<value>/mr-history/tmp</value>
	<description>Directory where history files are written by MapReduce jobs.</description>
  </property>

  <property>
    <name>mapreduce.jobhistory.done-dir</name>
	<value>/mr-history/done</value>
	<description>Directory where history files are managed by the MR JobHistory Server.</description>
  </property>

</configuration>
`)

func templateMapredSiteXmlGotplBytes() ([]byte, error) {
	return _templateMapredSiteXmlGotpl, nil
}

func templateMapredSiteXmlGotpl() (*asset, error) {
	bytes, err := templateMapredSiteXmlGotplBytes()
	if err != nil {
		return nil, err
	}

	info := bindataFileInfo{name: "template/mapred-site.xml.gotpl", size: 3034, mode: os.FileMode(420), modTime: time.Unix(1517859994, 0)}
	a := &asset{bytes: bytes, info: info}
	return a, nil
}

var _templateYarnSiteXmlGotpl = []byte(`<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>

<!-- Site specific YARN configuration properties -->
  <!-- Configurations for ResourceManager and NodeManager: -->
  <property>
    <name>yarn.acl.enable</name>
	<value>false</value>
	<description>Enable ACLs? Defaults to false.</description>
  </property>

  <property>
    <name>yarn.admin.acl</name>
	<value></value>
    <description>Admin ACL. ACL to set admins on the cluster. ACLs are of for comma-separated-usersspacecomma-separated-groups. Defaults to special value of * which means anyone. Special value of just space means no one has access.</description>
  </property>

  <property>
    <name>yarn.log-aggregation-enable</name>
	<value>false</value>
	<description>Configuration to enable or disable log aggregation</description>
  </property>

  <!-- Configurations for ResourceManager: -->
  <property>
    <name>yarn.resourcemanager.address</name>
	<value></value>
	<description>ResourceManager host:port for clients to submit jobs.	host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
	<value></value>
	<description>ResourceManager host:port for ApplicationMasters to talk to Scheduler to obtain resources.	host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
	<value></value>
	<description>ResourceManager host:port for NodeManagers.	host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.admin.address</name>
	<value></value>
	<description>ResourceManager host:port for administrative commands.	host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.webapp.address</name>
	<value></value>
	<description>ResourceManager web-ui host:port.	host:port If set, overrides the hostname set in yarn.resourcemanager.hostname.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.hostname</name>
	<value></value>
	<description>ResourceManager host.	host Single hostname that can be set in place of setting all yarn.resourcemanager*address resources. Results in default ports for ResourceManager components.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.scheduler.class</name>
	<value></value>
	<description>ResourceManager Scheduler class.	CapacityScheduler (recommended), FairScheduler (also recommended), or FifoScheduler. Use a fully qualified class name, e.g., org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.</description>
  </property>

  <property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
	<value></value>
	<description>Minimum limit of memory to allocate to each container request at the Resource Manager.	In MBs</description>
  </property>

  <property>
    <name>yarn.scheduler.maximum-allocation-mb</name>
	<value></value>
	<description>Maximum limit of memory to allocate to each container request at the Resource Manager.	In MBs</description>
  </property>

  <property>
    <name>yarn.resourcemanager.nodes.include-path</name>
	<value></value>
	<description>List of permitted/excluded NodeManagers.	If necessary, use these files to control the list of allowable NodeManagers.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.nodes.exclude-path</name>
	<value></value>
	<description>List of permitted/excluded NodeManagers.	If necessary, use these files to control the list of allowable NodeManagers.</description>
  </property>

  <!-- Configurations for NodeManager: -->
  <property>
    <name>yarn.nodemanager.resource.memory-mb</name>
	<value></value>
	<description>Resource i.e. available physical memory, in MB, for given NodeManager	Defines total available resources on the NodeManager to be made available to running containers</description>
  </property>

  <property>
    <name>yarn.nodemanager.vmem-pmem-ratio</name>
	<value></value>
	<description>Maximum ratio by which virtual memory usage of tasks may exceed physical memory	The virtual memory usage of each task may exceed its physical memory limit by this ratio. The total amount of virtual memory used by tasks on the NodeManager may exceed its physical memory usage by this ratio.</description>
  </property>

  <property>
    <name>yarn.nodemanager.local-dirs</name>
	<value></value>
	<description>Comma-separated list of paths on the local filesystem where intermediate data is written.	Multiple paths help spread disk i/o.</description>
  </property>

  <property>
    <name>yarn.nodemanager.log-dirs</name>
	<value></value>
	<description>Comma-separated list of paths on the local filesystem where logs are written.	Multiple paths help spread disk i/o.</description>
  </property>

  <property>
    <name>yarn.nodemanager.log.retain-seconds</name>
	<value>10800</value>
	<description>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.</description>
  </property>

  <property>
    <name>yarn.nodemanager.remote-app-log-dir</name>
	<value>/logs</value>
	<description>HDFS directory where the application logs are moved on application completion. Need to set appropriate permissions. Only applicable if log-aggregation is enabled.</description>
  </property>

  <property>
    <name>yarn.nodemanager.remote-app-log-dir-suffix</name>
	<value>logs</value>
	<description>Suffix appended to the remote log dir. Logs will be aggregated to ${yarn.nodemanager.remote-app-log-dir}/${user}/${thisParam} Only applicable if log-aggregation is enabled.</description>
  </property>

  <property>
    <name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
	<description>Shuffle service that needs to be set for Map Reduce applications.</description>
  </property>

  <property>
    <name>yarn.nodemanager.env-whitelist</name>
	<value></value>
	<description>Environment properties to be inherited by containers from NodeManagers	For mapreduce application in addition to the default values HADOOP_MAPRED_HOME should to be added. Property value should JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</description>
  </property>

  <!-- Configurations for History Server (Needs to be moved elsewhere): -->
  <property>
    <name>yarn.log-aggregation.retain-seconds</name>
	<value>-1</value>
	<description>How long to keep aggregation logs before deleting them. -1 disables. Be careful, set this too small and you will spam the name node.</description>
  </property>

  <property>
    <name>yarn.log-aggregation.retain-check-interval-seconds</name>
	<value>-1</value>
	<description>Time between checks for aggregated log retention. If set to 0 or a negative value then the value is computed as one-tenth of the aggregated log retention time. Be careful, set this too small and you will spam the name node.</description>
  </property>

  <!-- Monitoring Health of NodeManagers -->
  <property>
    <name>yarn.nodemanager.health-checker.script.path</name>
	<value></value>
	<description>Node health script	Script to check for node’s health status.</description>
  </property>

  <property>
    <name>yarn.nodemanager.health-checker.script.opts</name>
	<value></value>
	<description>Node health script options	Options for script to check for node’s health status.</description>
  </property>

  <property>
    <name>yarn.nodemanager.health-checker.interval-ms</name>
	<value></value>
	<description>Node health script interval	Time interval for running health script.</description>
  </property>

  <property>
    <name>yarn.nodemanager.health-checker.script.timeout-ms</name>
	<value></value>
	<description>Node health script timeout interval	Timeout for health script execution.</description>
  </property>

</configuration>
`)

func templateYarnSiteXmlGotplBytes() ([]byte, error) {
	return _templateYarnSiteXmlGotpl, nil
}

func templateYarnSiteXmlGotpl() (*asset, error) {
	bytes, err := templateYarnSiteXmlGotplBytes()
	if err != nil {
		return nil, err
	}

	info := bindataFileInfo{name: "template/yarn-site.xml.gotpl", size: 8639, mode: os.FileMode(420), modTime: time.Unix(1517861456, 0)}
	a := &asset{bytes: bytes, info: info}
	return a, nil
}

// Asset loads and returns the asset for the given name.
// It returns an error if the asset could not be found or
// could not be loaded.
func Asset(name string) ([]byte, error) {
	cannonicalName := strings.Replace(name, "\\", "/", -1)
	if f, ok := _bindata[cannonicalName]; ok {
		a, err := f()
		if err != nil {
			return nil, fmt.Errorf("Asset %s can't read by error: %v", name, err)
		}
		return a.bytes, nil
	}
	return nil, fmt.Errorf("Asset %s not found", name)
}

// MustAsset is like Asset but panics when Asset would return an error.
// It simplifies safe initialization of global variables.
func MustAsset(name string) []byte {
	a, err := Asset(name)
	if err != nil {
		panic("asset: Asset(" + name + "): " + err.Error())
	}

	return a
}

// AssetInfo loads and returns the asset info for the given name.
// It returns an error if the asset could not be found or
// could not be loaded.
func AssetInfo(name string) (os.FileInfo, error) {
	cannonicalName := strings.Replace(name, "\\", "/", -1)
	if f, ok := _bindata[cannonicalName]; ok {
		a, err := f()
		if err != nil {
			return nil, fmt.Errorf("AssetInfo %s can't read by error: %v", name, err)
		}
		return a.info, nil
	}
	return nil, fmt.Errorf("AssetInfo %s not found", name)
}

// AssetNames returns the names of the assets.
func AssetNames() []string {
	names := make([]string, 0, len(_bindata))
	for name := range _bindata {
		names = append(names, name)
	}
	return names
}

// _bindata is a table, holding each asset generator, mapped to its name.
var _bindata = map[string]func() (*asset, error){
	"template/core-site.xml.gotpl": templateCoreSiteXmlGotpl,
	"template/hdfs-node-service.yaml.gotpl": templateHdfsNodeServiceYamlGotpl,
	"template/hdfs-node-statefulset.yaml.gotpl": templateHdfsNodeStatefulsetYamlGotpl,
	"template/hdfs-site.xml.gotpl": templateHdfsSiteXmlGotpl,
	"template/mapred-site.xml.gotpl": templateMapredSiteXmlGotpl,
	"template/yarn-site.xml.gotpl": templateYarnSiteXmlGotpl,
}

// AssetDir returns the file names below a certain
// directory embedded in the file by go-bindata.
// For example if you run go-bindata on data/... and data contains the
// following hierarchy:
//     data/
//       foo.txt
//       img/
//         a.png
//         b.png
// then AssetDir("data") would return []string{"foo.txt", "img"}
// AssetDir("data/img") would return []string{"a.png", "b.png"}
// AssetDir("foo.txt") and AssetDir("notexist") would return an error
// AssetDir("") will return []string{"data"}.
func AssetDir(name string) ([]string, error) {
	node := _bintree
	if len(name) != 0 {
		cannonicalName := strings.Replace(name, "\\", "/", -1)
		pathList := strings.Split(cannonicalName, "/")
		for _, p := range pathList {
			node = node.Children[p]
			if node == nil {
				return nil, fmt.Errorf("Asset %s not found", name)
			}
		}
	}
	if node.Func != nil {
		return nil, fmt.Errorf("Asset %s not found", name)
	}
	rv := make([]string, 0, len(node.Children))
	for childName := range node.Children {
		rv = append(rv, childName)
	}
	return rv, nil
}

type bintree struct {
	Func     func() (*asset, error)
	Children map[string]*bintree
}
var _bintree = &bintree{nil, map[string]*bintree{
	"template": &bintree{nil, map[string]*bintree{
		"core-site.xml.gotpl": &bintree{templateCoreSiteXmlGotpl, map[string]*bintree{}},
		"hdfs-node-service.yaml.gotpl": &bintree{templateHdfsNodeServiceYamlGotpl, map[string]*bintree{}},
		"hdfs-node-statefulset.yaml.gotpl": &bintree{templateHdfsNodeStatefulsetYamlGotpl, map[string]*bintree{}},
		"hdfs-site.xml.gotpl": &bintree{templateHdfsSiteXmlGotpl, map[string]*bintree{}},
		"mapred-site.xml.gotpl": &bintree{templateMapredSiteXmlGotpl, map[string]*bintree{}},
		"yarn-site.xml.gotpl": &bintree{templateYarnSiteXmlGotpl, map[string]*bintree{}},
	}},
}}

// RestoreAsset restores an asset under the given directory
func RestoreAsset(dir, name string) error {
	data, err := Asset(name)
	if err != nil {
		return err
	}
	info, err := AssetInfo(name)
	if err != nil {
		return err
	}
	err = os.MkdirAll(_filePath(dir, filepath.Dir(name)), os.FileMode(0755))
	if err != nil {
		return err
	}
	err = ioutil.WriteFile(_filePath(dir, name), data, info.Mode())
	if err != nil {
		return err
	}
	err = os.Chtimes(_filePath(dir, name), info.ModTime(), info.ModTime())
	if err != nil {
		return err
	}
	return nil
}

// RestoreAssets restores an asset under the given directory recursively
func RestoreAssets(dir, name string) error {
	children, err := AssetDir(name)
	// File
	if err != nil {
		return RestoreAsset(dir, name)
	}
	// Dir
	for _, child := range children {
		err = RestoreAssets(dir, filepath.Join(name, child))
		if err != nil {
			return err
		}
	}
	return nil
}

func _filePath(dir, name string) string {
	cannonicalName := strings.Replace(name, "\\", "/", -1)
	return filepath.Join(append([]string{dir}, strings.Split(cannonicalName, "/")...)...)
}

